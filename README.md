# Container Network Segmentation Lab

This project is a self-contained lab that simulates a small, segmented enterprise network using Docker. It is designed to demonstrate:

- Network segmentation across public, private, and management networks
- Multi-tier application architecture (frontend → API → database)
- Host-based firewalling with iptables inside a container
- Policy-as-code for defining allowed network flows
- Automated connectivity testing and a small web dashboard
- An attacker perspective from the public network

The lab is meant to be readable, reproducible, and useful as both a portfolio project and a teaching tool.

---

## High-Level Overview

The environment is built out of multiple Docker containers:

- A **frontend** web server reachable from the host
- An **API** service that talks to a **PostgreSQL** database
- A **management (mgmt)** container acting as a jump host
- An **attacker** container on the public network
- A **dashboard** that visualizes connectivity test results

Three Docker networks are used:

- `public_net` – internet-facing zone (frontend, attacker, API)
- `private_net` – internal application/data zone (API, DB, mgmt)
- `mgmt_net` – management zone (mgmt only)

Only specific containers are attached to each network, which enforces segmentation by design.

---

## Architecture

### Network Topology

```text
                +---------------------------+
                |        public_net         |
                |                           |
   Host 8080 -> | [frontend]                |
                |                           |
   Host 5001 -> | [api]                     |
                |                           |
                | [attacker]                |
                +-------------+-------------+
                              |
                              | (api is on both nets)
                              v
                +----------------------------+
                |         private_net        |
                |                            |
                |  [api]  [db]  [mgmt]       |
                +-------------+--------------+
                              |
                              v
                +----------------------------+
                |          mgmt_net          |
                |                            |
                |          [mgmt]           |
                +----------------------------+
```

````

### Services

**frontend**

- Nginx serving static HTML on port 80
- Network: `public_net`
- Exposed to host as: `http://localhost:8080`

**api**

- Flask application running on port 5000
- Talks to Postgres using `pg8000`
- Network: `public_net` and `private_net`
- Exposed to host as: `http://localhost:5001`
- Has `NET_ADMIN` capability and `iptables` installed to enforce host-level firewall rules

**db**

- PostgreSQL 16 instance
- Network: `private_net` only
- Not exposed to the host

**mgmt**

- Lightweight management/jump container with tools like `curl`, `ping`, and `nc`
- Networks: `private_net` and `mgmt_net`
- No ports exposed to the host

**dashboard**

- Flask application serving a simple HTML dashboard
- Reads `results.json` generated by the connectivity test script
- Exposed to host as: `http://localhost:8000`

**attacker**

- Attacker simulation container with `nmap` and `curl`
- Network: `public_net` only
- Used to scan and probe `frontend` and `api` from the “internet” side

---

## What This Lab Demonstrates

1. **Network segmentation**

   - `frontend` can reach `api`, but not `db` or `mgmt`.
   - `db` and `mgmt` cannot reach `frontend` (no shared network).
   - The attacker container cannot reach `db` at all.

2. **Multi-tier application flow**

   - The host sends HTTP requests to `api` on port 5001.
   - The `api` container connects to `db` on port 5432 over `private_net`.
   - `GET /users` and `POST /users` use real database queries.

3. **Host-based firewalling**

   - Docker networking would normally allow `db -> api` on port 5000.
   - An iptables rule inside the `api` container explicitly drops that traffic.
   - This enforces “database cannot initiate connections to the API” even inside the private network.

4. **Policy-as-code + automated testing**

   - `policy.json` defines which flows are supposed to be allowed.
   - `connectivity_test.py`:

     - Builds a ping connectivity matrix (who can reach whom by name).
     - Tests TCP connectivity for each defined flow using `nc`.
     - Writes structured output to `results.json` and prints a summary.

5. **Visibility via dashboard**

   - The dashboard reads `results.json` and shows:

     - A ping matrix table.
     - A table of policy-based TCP checks with statuses.

6. **Attacker perspective**

   - The attacker container runs `attack.sh` which:

     - Scans `frontend` and `api` with `nmap`.
     - Attempts HTTP requests.
     - Attempts to reach `db` and fails due to segmentation.

---

## Prerequisites

- Docker Desktop (macOS/Windows) or Docker Engine + docker-compose (Linux)
- Python 3 installed on the host (for running `connectivity_test.py`)

---

## Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/Zachary200114/container-network-seg-lab.git
cd container-network-seg-lab
```

### 2. Build and start the environment

From the project root:

```bash
docker compose up -d --build
```

This will:

- Build images for `frontend`, `api`, `mgmt`, `dashboard`, `attacker`
- Pull the Postgres base image
- Create the three Docker networks
- Start all containers in the background

Check that everything is running:

```bash
docker compose ps
```

You should see each service with a status of `Up`, and:

- `frontend` mapped to `0.0.0.0:8080->80/tcp`
- `api` mapped to `0.0.0.0:5001->5000/tcp`
- `dashboard` mapped to `0.0.0.0:8000->8000/tcp`

---

## Application: API ↔ Database

The `api` service exposes a small HTTP API and uses Postgres over `private_net`.

### Endpoints

**Health check**

```bash
curl http://localhost:5001/health
```

Response:

```json
{ "status": "ok", "service": "api" }
```

**List users**

```bash
curl http://localhost:5001/users
```

Initially, this should return an empty list:

```json
[]
```

**Create a user**

```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{"name":"Alice","email":"alice@example.com"}' \
  http://localhost:5001/users
```

Example response:

```json
{ "id": 1, "name": "Alice", "email": "alice@example.com" }
```

**Verify data is stored**

```bash
curl http://localhost:5001/users
```

Example:

```json
[
  {
    "id": 1,
    "name": "Alice",
    "email": "alice@example.com"
  }
]
```

All of this traffic flows:

- From your host → `api` on port 5001 (mapped to container port 5000)
- From `api` → `db` on port 5432 over `private_net`

---

## Network Connectivity Testing

The script `connectivity_test.py` automates verification of segmentation and allowed flows.

### 1. Ping connectivity matrix

From the project root:

```bash
python3 connectivity_test.py
```

The script:

- Loops over all containers: `frontend`, `api`, `db`, `mgmt`.
- Uses `docker exec` + `ping` to test each pair by container name.
- Prints a matrix like:

```text
Ping connectivity matrix (by container name):

From\To  frontend  api  db   mgmt
frontend SELF      OK   X    X
api      OK        SELF OK   OK
db       X         OK   SELF OK
mgmt     X         OK   OK   SELF
```

Interpretation:

- `frontend` can only ping `api`.
- `api` can ping everyone (it sits on both networks).
- `db` and `mgmt` cannot directly ping `frontend`.

### 2. Policy-based TCP checks

Allowed flows are declared in `policy.json`, for example:

```json
{
  "allowed_flows": [
    {
      "from": "frontend",
      "to": "api",
      "ports": [5000]
    },
    {
      "from": "api",
      "to": "db",
      "ports": [5432]
    },
    {
      "from": "mgmt",
      "to": "api",
      "ports": [5000]
    },
    {
      "from": "mgmt",
      "to": "db",
      "ports": [5432]
    },
    {
      "from": "db",
      "to": "api",
      "ports": [5000]
    }
  ]
}
```

The script:

- For each entry, runs `nc -z -w 1 <dst> <port>` from inside `<src>`.
- Records results as:

  - `OK` – TCP connect succeeded
  - `X` – TCP connect failed

- Prints a summary, for example:

```text
Policy-based TCP connectivity check:

frontend -> api:5000 => OK
api -> db:5432       => OK
mgmt -> api:5000     => OK
mgmt -> db:5432      => OK
db -> api:5000       => X
```

The last line is particularly important: `db -> api:5000 => X` is the result of the iptables rule described below.

### 3. JSON output

Every run also writes a machine-readable file:

- `results.json` in the project root

This contains:

- Timestamp
- Ping results
- Policy-based TCP results

The dashboard uses this file.

---

## Host-Based Firewall on `api` (iptables)

Although Docker networking would allow the database container to connect to the API container on port 5000, the lab uses iptables inside `api` to block that specific flow.

The `api` service is given `NET_ADMIN` capability in `docker-compose.yml`:

```yaml
api:
  build: ./api
  container_name: api
  cap_add:
    - NET_ADMIN
  networks:
    - public_net
    - private_net
  ports:
    - "5001:5000"
```

Inside the `api` container, the iptables rule looks like:

```bash
iptables -A INPUT -p tcp --dport 5000 -s db.container-network-seg-lab_private_net -j DROP
```

This means:

- If a TCP packet arrives on port 5000
- And its source is the `db` container
- The packet is dropped

As a result, `db -> api:5000` fails the TCP check, and `connectivity_test.py` reports `X`, even though the path exists at the Docker network level. This demonstrates host-based enforcement of least privilege.

You can inspect and manipulate rules by entering the container:

```bash
docker exec -it api sh
iptables -L
```

---

## Dashboard

The `dashboard` service is a minimal Flask application that reads `results.json` and renders:

- The last updated timestamp
- A table of ping results
- A table of policy-based TCP check results

To update the data:

```bash
python3 connectivity_test.py
```

Then visit:

```text
http://localhost:8000
```

You can use this view when explaining the lab to others: it gives a quick visual overview of segmentation status and policy adherence.

---

## Attacker Simulation

The `attacker` container is attached only to `public_net` and has basic offensive tools installed.

To run the built-in attack script:

```bash
docker exec attacker ./attack.sh
```

The script:

- Prints environment and IP info for the attacker container
- Uses `nslookup` to see which container names it can resolve
- Runs `nmap` scans against:

  - `frontend`
  - `api`

- Sends HTTP requests to:

  - `http://frontend/`
  - `http://api:5000/`

- Attempts to scan `db` (which fails due to segmentation)

This gives you a realistic “from the internet” view:

- The attacker can see the frontend and API
- The attacker cannot see or reach the database directly

---

## Frontend

The frontend is a simple Nginx container serving a static page. It demonstrates an internet-facing entry point without adding unnecessary complexity.

Visit:

```text
http://localhost:8080
```

You should see a basic HTML page identifying the frontend container and indicating that it lives on `public_net`.

---

## Stopping and Resetting the Lab

To stop all containers:

```bash
docker compose down
```

To stop all containers and remove volumes/networks:

```bash
docker compose down -v
```

To bring it back up:

```bash
docker compose up -d --build
python3 connectivity_test.py
```

---

## Using This as a Teaching or Portfolio Project

This lab is suitable for:

- Demonstrating understanding of network segmentation and zero-trust principles
- Showing hands-on experience with Docker, Docker Compose, and Linux networking tools
- Discussing defense in depth:

  - Segmentation
  - Host-based firewalls
  - Policy-as-code
  - Observability via dashboards

- Walking others through practical security concepts using a reproducible environment

For guided exercises and ideas on how to extend the lab, see [`LAB.md`](./LAB.md).

```

```
````
